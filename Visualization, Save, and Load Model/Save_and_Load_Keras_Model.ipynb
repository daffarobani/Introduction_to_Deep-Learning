{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure that h5py library installed\n",
    "# --> pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 694us/step - loss: 0.4684 - accuracy: 0.7721\n",
      "Accuracy: 77.21%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Main Script\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import os\n",
    "\n",
    "#Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "#Load the dataset\n",
    "dataset = loadtxt(r'C:\\Users\\LEGION\\Machine_Learning_Learn_Project\\Intro_Deep_Learning\\pima-indians-diabetes.csv', delimiter=',')\n",
    "#Split into X and y\n",
    "nvar = dataset.shape[1]-1\n",
    "X = dataset[:,:nvar]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "##Define keras model\n",
    "\n",
    "#In this example, use a fully-connected network structure with three layes\n",
    "#Fully connected layers are defined using the Dense class.\n",
    "#Use ReLU for the activation function of the first two layers and Sigmoid in the output layer.\n",
    "\n",
    "#Define keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "##Compile Keras model\n",
    "\n",
    "#Use cross entropy as the loss argument.\n",
    "#Use adam optimizer, a popular version of stochastic gradient descent algorithm since it automatically tunes itself and gives\n",
    "#good results for a wide range of problems.\n",
    "#Use accuracy for metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "##Fit Keras Model\n",
    "\n",
    "#Epoch: One pass through all of the rows in the training dataset.\n",
    "#Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "##Evaluate Keras Model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))\n",
    "\n",
    "#Serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "#Serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "24/24 [==============================] - 0s 608us/step - loss: 0.4965 - accuracy: 0.7407\n",
      "Accuracy: 77.21%\n"
     ]
    }
   ],
   "source": [
    "#Load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "#Load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "#Evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "_, accuracy = loaded_model.evaluate(X, y)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model to YAML\n",
    "#The YAML format is used for model specification.\n",
    "#Make sure that PyYAML 5 installed\n",
    "# --> pip install PyYAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 651us/step - loss: 0.4677 - accuracy: 0.7786\n",
      "Accuracy: 77.86%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Main Script\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_yaml\n",
    "import os\n",
    "\n",
    "#Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "#Load the dataset\n",
    "dataset = loadtxt(r'C:\\Users\\LEGION\\Machine_Learning_Learn_Project\\Intro_Deep_Learning\\pima-indians-diabetes.csv', delimiter=',')\n",
    "#Split into X and y\n",
    "nvar = dataset.shape[1]-1\n",
    "X = dataset[:,:nvar]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "##Define keras model\n",
    "\n",
    "#In this example, use a fully-connected network structure with three layes\n",
    "#Fully connected layers are defined using the Dense class.\n",
    "#Use ReLU for the activation function of the first two layers and Sigmoid in the output layer.\n",
    "\n",
    "#Define keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "##Compile Keras model\n",
    "\n",
    "#Use cross entropy as the loss argument.\n",
    "#Use adam optimizer, a popular version of stochastic gradient descent algorithm since it automatically tunes itself and gives\n",
    "#good results for a wide range of problems.\n",
    "#Use accuracy for metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "##Fit Keras Model\n",
    "\n",
    "#Epoch: One pass through all of the rows in the training dataset.\n",
    "#Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "##Evaluate Keras Model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))\n",
    "\n",
    "#Serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\",\"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "#Serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "24/24 [==============================] - 0s 720us/step - loss: 0.4940 - accuracy: 0.7504\n",
      "Accuracy: 77.86%\n"
     ]
    }
   ],
   "source": [
    "#Load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "#Load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "#Evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "_, accuracy = loaded_model.evaluate(X, y)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save Model Weights and Architecture Together\n",
    "#Save both model weights and architecture together to single H5 file\n",
    "#including: Model weights, model architecture, model compilation details (loss and metrics), model optimizer state\n",
    "#This is the preferred ways to save and load Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 607us/step - loss: 0.4820 - accuracy: 0.7656\n",
      "Accuracy: 76.56%\n",
      "Saved to disk\n"
     ]
    }
   ],
   "source": [
    "#Save Model\n",
    "\n",
    "#Main Script\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_yaml\n",
    "import os\n",
    "\n",
    "#Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "#Load the dataset\n",
    "dataset = loadtxt(r'C:\\Users\\LEGION\\Machine_Learning_Learn_Project\\Intro_Deep_Learning\\pima-indians-diabetes.csv', delimiter=',')\n",
    "#Split into X and y\n",
    "nvar = dataset.shape[1]-1\n",
    "X = dataset[:,:nvar]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "##Define keras model\n",
    "\n",
    "#In this example, use a fully-connected network structure with three layes\n",
    "#Fully connected layers are defined using the Dense class.\n",
    "#Use ReLU for the activation function of the first two layers and Sigmoid in the output layer.\n",
    "\n",
    "#Define keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "##Compile Keras model\n",
    "\n",
    "#Use cross entropy as the loss argument.\n",
    "#Use adam optimizer, a popular version of stochastic gradient descent algorithm since it automatically tunes itself and gives\n",
    "#good results for a wide range of problems.\n",
    "#Use accuracy for metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "##Fit Keras Model\n",
    "\n",
    "#Epoch: One pass through all of the rows in the training dataset.\n",
    "#Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "\n",
    "##Evaluate Keras Model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))\n",
    "\n",
    "#Save model and architecture to single file\n",
    "model.save('model_full.h5')\n",
    "print('Saved to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "24/24 [==============================] - 0s 638us/step - loss: 0.4820 - accuracy: 0.7656\n",
      "Accuracy: 76.56%\n"
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "\n",
    "#Load model\n",
    "model = load_model('model_full.h5')\n",
    "\n",
    "#Summarize model\n",
    "model.summary()\n",
    "\n",
    "#Load dataset\n",
    "dataset = loadtxt(r'C:\\Users\\LEGION\\Machine_Learning_Learn_Project\\Intro_Deep_Learning\\pima-indians-diabetes.csv', delimiter=',')\n",
    "#Split into X and y\n",
    "nvar = dataset.shape[1]-1\n",
    "X = dataset[:,:nvar]\n",
    "y = dataset[:,-1]\n",
    "\n",
    "##Evaluate Keras Model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f%%' %(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
